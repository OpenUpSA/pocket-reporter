{
  "body": "# Toolkit\n\nTOOLKIT NO. 1 PRODUCED BY IDASA’S WORD_ON_THE_STREET_ ([www.wordonthestreet.org.za](www.wordonthestreet.org.za))\n\n**Reporting on public opinion surveys**\n\nM\redia organisations, governments and businesses regularly make use of public opinion surveys as a way of finding out how members of\r the public feel about all sorts of issues.\r\n\nOpinion surveys are widely used in the run-up\r to elections, as a way of trying to predict the outcome or measure\r the success of the parties’ campaigns. But public opinion surveys\r increasingly play a role in-between elections too.\r\n\nOpinion surveys can be a rich and useful resource for journalists,\r but if journalists wish to benefit from this tool, they need to understand it. They need to know how surveys work, how to evaluate\r them, and how to interpret them. \n\n**This toolkit provides\r some basic guidelines to\r assist journalists in\r knowing how surveys\r work, how to evaluate\r them and how to\r interpret them.**\n\n****\n\n**Introduction**\n\nRegular elections are seen as the most\r important way for citizens in a democracy to make their views known. But elections have limitations. For one thing, they\r are rather infrequent – most are held only\r every 4 or 5 years. Secondly, when elections do come around, not everybody participates – in some countries less than half of the population turns\r out to vote. Finally, elections are rather blunt instruments – citizens\r have just one vote per ballot paper. That is very useful when it\r comes to making a single choice, such as who should be the ruling\r party, but it’s not a useful way for citizens to reveal a range of preferences.\r\n\nIf they are to be responsive to citizens’ preferences, then in\r between elections, government, business, and social institutions\r need a timely and accurate flow of information on citizens’ preferences, needs and behaviour. So, while public opinion surveys are\r often done in the run-up to elections, they increasingly play a role\r in-between elections too. Media organisations, governments and\r businesses regularly make use of public opinion surveys as a way\r of measuring public sentiment.\r\n\nIn many parts of the world, survey researchers and news media\r are viewed as natural allies. If news media see themselves as “watchdogs” or “guardians of the public interest,” then opinion\r surveys are far better guides to what the public want and think than\r the typical “man on the street” or “voxpop” interview. In North\r America, Western Europe and Japan, many large news organisations maintain in-house survey departments, and regularly conduct\r surveys or polls to find out how people feel about the key issues of\r the day. At election time and during other critical events, such surveys can play a powerful role in focusing attention on ordinary\r people’s viewpoints and priorities. Often, these turn out to be\r rather different from those of the elite groups who usually hog the\r headlines. \n\n\n\nSurveys are useful for many reasons.\r In contrast to elections, they can be done\r at any time, and as frequently as\r resources permit. They can count voters\r and non-voters equally, or compare them.\r They can help separate values, evaluations, policy preferences from the vote\r and they can distinguish among several\r preferences or evaluations.\r So, surveys can be both a benefit and\r threat to governments, parties and organisations. For those who are truly interested, surveys let us know what citizens are thinking and what they\r want. For those who are interested in “leading” or “educating” the\r public, surveys provide a key source of information (“intelligence”). For those who are involved in policy debate, public opinion can be a tool (if the people support you) or a threat (if they\r oppose you). That is why, in most modern democracies, opinion\r surveys are increasingly viewed as one of the most important communication links between governments and the governed. \n\n\n\n**What is a public opinion survey?**\r\n\nA survey is a method of gathering information from a sample of\r individuals within a particular group or population. This information is then used to draw conclusions about the entire group or population.\n\n\n\nThe idea of a ‘sample’ is crucial. A survey is not like a census.\r In a census, all members of the population are studied. In a survey,\r a sample is selected. They key to a scientific survey is that the\r chance (or probability) or every unit (or person) in the population\r being selected for the sample, must be known. In a purely random\r sample, each unit in the population must have the same probability of being selected.\r\n\nA survey is also different from a focus group. In a focus group,\r several people are encouraged by a group leader to voice their\r reactions to various issues. Focus groups may provide interesting\r insight for certain purposes, but they cannot be used to draw inferences about the larger population, because they do not make use of\r systematic, random sampling.\r\n\nA public opinion survey focuses on individuals – the individual\r is the unit of measurement. Thus, it is different from a household\r survey, which has the entire household as its unit of measurement.\r\n\nA public opinion survey gathers information about just that:\r opinions – people’s preferences or evaluations. It does not look at\r behaviour, such as whether people are looking for jobs, or how\r people spend their money\n\n\n\n**Are surveys accurate?**\r\n\nThe results of a survey can be used to draw inferences about an\r entire population for a number of reasons. Firstly, samples are scientifically chosen, so that each person in the population will have\r an equal and known chance of being selected. Secondly, information is collected in a standardised way, so that every individual is\r asked the same questions in the same way.\r\n\nSurveys that follow a sound methodology can thus provide a\r very accurate insight into people’s opinions. But surveys also have\r their limitations. For one thing, they should be seen as a ‘snapshot’\r of people’s views, at a particular time. As circumstances change, or\r new information is made public, people’s opinions may also\r change. This is particularly true of polls during election campaigns, where survey results might change from week to week, or\r even day to day.\r\n\nSeveral factors can impact on the results of a survey. One important factor is sampling error. This means that the results from the\r sample group differ from the results that would be found in the\r population as a whole, because the sample doesn’t accurately\r reflect the broader population. One common source of sampling\r error is the way in which surveys are conducted. For example, a\r survey that uses only telephonic interviews to gather people’s\r responses cannot claim to be representative of the whole South\r African population, as millions of South Africans do not have\r phones and they would have been excluded from participating.\r\n\nThere are also many kinds of non-sampling error that can affect\r the accuracy of a survey. Question Design and question order are\r very important, as the way in which questions are worded and\r organised can have a dramatic impact on the survey results.\r Another problem with surveys is that people may not be comfortable revealing their real opinions. This could happen in cases\r where there are large cultural, economic and other differences\r between the interviewers and interviewees. Language is another\r potential source of error. If surveys are conducted in a language\r other than people’s home language, there is a danger that respondents will misunderstand the questions, or that their answers will\r be misunderstood. On the other hand, if a survey questionnaire is\r translated into people’s home languages, there is the danger that the translated questions may not all be asking exactly the same\r thing. Thus, the answers from different language groups may not\r be able to be compared with one another. Strict measures and\r checks have to be put into place to ensure that translated questionnaires are all uniform.\r\n\n“Fake” surveys: It is important to beware of surveys that are not\r conducted scientifically. This includes any survey in which the\r respondents select themselves. Examples are polls on the Internet,\r where visitors to a web-site are asked to ‘vote’ on one issue or\r another, or polls conducted by newspapers or radio and television\r stations, where listeners and viewers are asked to call or SMS to\r indicate their preferences. In all these cases, it is the respondents\r themselves who decide to participate, and the group of respondents\r is thus not likely to be representative of the broader population in\r general. Such polls may be fun and entertaining, but they cannot\r claim to give us insight into the general, ‘public’opinion.\r\n\nWhile there are many possible sources of error, surveys that are\r conducted according to sound scientific methods can provide highly accurate insights into public opinion.\n\n\n\n## **Key questions every journalist should ask**\r\n\n**Who conducted the poll?**\r\n\nYou need to know this, so you can get all the information from\r them that will assist you to evaluate the survey and to follow up on\r stories. You should also be able to find out whether the organisation conducting the poll is a reputable one, with a good track\r record.\r\n\n**Who commissioned it, and why?**\r\n\nThe answer to this question will help you evaluate the validity of\r the survey. For example, if the survey was commissioned by a special interest group, a political party or a private corporation, you\r should be very careful, since such bodies usually commission\r research in order to achieve a specific goal, and this might have led\r to bias in the sampling, the timing, the phrasing of questions, or the\r interpretation of data.\r\n\n**Who does the survey cover?**\r\n\n(What universe did the survey cover?)\r\n\nIs the survey claiming to survey the views of all citizens of your\r country, or only a specific group?\r\n\n**What was the sampling method?**\r\n\n(How were the interviewees selected?)\r\n\nYou need to know whether the researcher used a specific scientific method for picking respondents, or whether people volunteered\r to participate (a sure sign of an unscientific survey).\r\n\nYou need to know whether the sampling was done in order to\r reflect the diversity of the population. (For example, if 20% of the\r country’s population lives in Province A, then 20% of the individuals in the sample must be from Province A. If 40% of the country\r lives in rural areas, then 40% of people in the sample must be from\r rural areas. If the population is 48% male and 52% female, then\r this must also be true of the sample – all depending on what the\r survey is claiming to measure.)\r\n\n**What was the sampling error? (overall, and for any subgroups)**\r\n\nThis is important. For example, if the survey says that 52% of",
  "spa": {},
  "nso": {},
  "afr": {},
  "tsn": {},
  "zul": {},
  "por": {},
  "sot": {},
  "title": "Media and Surveys",
  "type": "resources",
  "xho": {}
}